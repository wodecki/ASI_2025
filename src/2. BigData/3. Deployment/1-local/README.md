# Stage 1: Local Development ğŸ–¥ï¸

## ğŸ¯ Educational Purpose

This module introduces the fundamentals of **microservices architecture** in the ML context:

- **Backend (FastAPI):** REST API serving ML model
- **Frontend (Streamlit):** Interactive user interface
- **Communication:** HTTP requests between components

**Level:** Beginner
**Time:** 1-2 hours
**Requirements:** Python 3.11, uv package manager

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USER (Browser)     â”‚
â”‚   localhost:8501     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ Interacts with UI
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit Frontend  â”‚  Port 8501
â”‚  (frontend/app.py)   â”‚
â”‚                      â”‚
â”‚  - Item selection    â”‚
â”‚  - Predict button    â”‚
â”‚  - Results display   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚ HTTP GET
           â”‚ requests.get("http://localhost:8003/predict/{item}")
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backend     â”‚  Port 8003
â”‚  (backend/main.py)   â”‚
â”‚                      â”‚
â”‚  @startup:           â”‚
â”‚  - Load model        â”‚ â† AutoGluon TimeSeriesPredictor
â”‚  - Load data         â”‚ â† iowa_sales.csv
â”‚                      â”‚
â”‚  @request:           â”‚
â”‚  - Generate forecast â”‚
â”‚  - Return JSON       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Step 0: Prerequisites

**Install uv (if not already installed):**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Step 1: Train the Model (Backend - Terminal 1)

**IMPORTANT:** This deployment is self-contained. You must train the model first.

```bash
cd backend/
uv sync                  # Install dependencies (first time only)
uv run python "1. train.py"  # Train model (~60 seconds)
```

**Expected output:**
```
============================================================
Iowa Sales Time Series Model Training
============================================================
Step 1: Loading data from data/iowa_sales.csv
âœ“ Loaded 2034 rows
âœ“ Products: 5
...
Training in progress... (this takes ~60 seconds)
...
Training Complete!
âœ“ Model saved to: autogluon-iowa-daily/
```

**Note for Intel Mac users:** The project includes a fix for torch compatibility.

### Step 2: Run Backend Server (Terminal 1)

```bash
# Still in backend/ directory
uv run uvicorn main:app --reload --host 0.0.0.0 --port 8003
```

**Expected output:**
```
INFO: Loading AutoGluon predictor...
INFO: âœ“ Predictor loaded successfully
INFO: Loading and preprocessing training data...
INFO: âœ“ Data loaded: 2034 records, 5 unique items
INFO: ============================================================
INFO: Backend ready! API available at http://localhost:8003
INFO: ============================================================
INFO: Uvicorn running on http://0.0.0.0:8003
```

### Step 3: Test Backend (Terminal 2)

```bash
# Health check
curl http://localhost:8003/

# Get available items
curl http://localhost:8003/items

# Get prediction
curl "http://localhost:8003/predict/BLACK%20VELVET"
```

### Step 4: Run Frontend (Terminal 2 or 3)

```bash
cd frontend/
uv sync                  # Install dependencies (first time only)
uv run streamlit run app.py
```

**Streamlit will open automatically in browser:** http://localhost:8501

### Step 5: Use the Application

1. Select product from dropdown (e.g., "BLACK VELVET")
2. Click "ğŸ”® Generate Forecast"
3. View results:
   - Table with 7-day forecasts
   - Line chart
   - Raw JSON response

## ğŸ“‚ Project Structure

```
1-local/
â”œâ”€â”€ README.md                        # This file
â”‚
â”œâ”€â”€ backend/                         # FastAPI REST API
â”‚   â”œâ”€â”€ 1. train.py                  # Model training script (run first!)
â”‚   â”œâ”€â”€ main.py                      # Application code
â”‚   â”œâ”€â”€ pyproject.toml               # Dependencies (uv format, includes torch fix)
â”‚   â”œâ”€â”€ README.md                    # Backend documentation
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ iowa_sales.csv           # Training data (2034 rows, 5 products)
â”‚   â””â”€â”€ autogluon-iowa-daily/        # Generated by 1. train.py
â”‚
â””â”€â”€ frontend/                        # Streamlit UI
    â”œâ”€â”€ app.py                       # Application code
    â”œâ”€â”€ pyproject.toml               # Dependencies (uv format)
    â””â”€â”€ README.md                    # Frontend documentation
```

## ğŸ’¡ Key Design Decisions

### Self-Contained Deployment

This deployment is **based on** the minimal training example (`2. BigData/2. Models/1. minimal`) but is **self-sustainable**:

- âœ… Includes its own training script (`1. train.py`)
- âœ… Uses the same data and model approach
- âœ… No external dependencies on other directories
- âœ… Can be distributed as a standalone project

This design allows students to:
1. Learn from the minimal example first
2. See the same patterns applied in deployment context
3. Work with deployment independently without cross-directory dependencies

## ğŸ”‘ Key Concepts

### 1. Microservices Architecture

**Why separate backend and frontend?**

âœ… **Advantages:**
- **Separation of concerns:** UI logic â‰  business logic
- **Independent scaling:** Backend and frontend can scale separately
- **Technology flexibility:** Different frameworks for different tasks
- **Team collaboration:** Frontend and backend teams can work in parallel

âŒ **Disadvantages (local):**
- Requires running 2 processes
- Network latency (though minimal locally)

### 2. RESTful API Design

**Backend Endpoints:**

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/` | GET | Health check |
| `/items` | GET | List available products |
| `/predict/{item}` | GET | Generate 7-day forecast |

**REST Principles:**
- **Stateless:** Each request is independent
- **Resource-based:** URLs represent resources (`/predict/BLACK_VELVET`)
- **HTTP methods:** GET for retrieval
- **JSON format:** Standard data exchange format

### 3. Efficient Resource Management

**Anti-Pattern (BAD):**
```python
@app.get("/predict/{item}")
def predict(item: str):
    predictor = load_model()        # âŒ Loads model on EVERY request (slow!)
    data = load_data()              # âŒ Reloads data every time
    return predictor.predict(data)
```

**Best Practice (GOOD):**
```python
# Load once at startup
predictor = None

@app.on_event("startup")
async def startup():
    global predictor
    predictor = load_model()        # âœ… Load once (fast requests!)

@app.get("/predict/{item}")
def predict(item: str):
    return predictor.predict(data)  # âœ… Use pre-loaded model
```

**Performance Impact:**
- Bad: ~5 seconds per request
- Good: ~200ms per request
- **25x speedup!**

### 4. Error Handling & User Experience

**Backend:** HTTP status codes
```python
if item_name not in predictions:
    raise HTTPException(status_code=404, detail="Item not found")
```

**Frontend:** User-friendly messages
```python
except requests.exceptions.ConnectionError:
    st.error("Cannot connect to backend. Is it running?")
```

## ğŸ“ Learning Objectives

After completing this module, you will be able to:

### Basics
- [ ] Run local backend and frontend
- [ ] Understand HTTP communication between components
- [ ] Test API via curl
- [ ] Use Swagger UI (http://localhost:8003/docs)

### Intermediate
- [ ] Explain the difference between monolith and microservices
- [ ] Implement RESTful endpoints
- [ ] Optimize loading zasobÃ³w (startup vs per-request)
- [ ] Handle errors i timeouts

### Advanced
- [ ] Understand async/await in FastAPI
- [ ] Add new endpoints to API
- [ ] Integrate new ML model
- [ ] Extend frontend o nowe funkcje

## ğŸ§ª Exercises

### Exercise 1: Add New Endpoint
Dodaj endpoint `/health` zwracajÄ…cy status systemu:
```json
{
  "status": "healthy",
  "model_loaded": true,
  "uptime_seconds": 123
}
```

**Hints:**
- Use `@app.get("/health")`
- Track startup time with `time.time()`
- Check if `predictor is not None`

### Exercise 2: Add Statistics
Rozszerz `/predict/{item}` o statystyki:
```json
{
  "item": "BLACK VELVET",
  "predictions": [...],
  "statistics": {
    "mean": 1245.67,
    "min": 1200.00,
    "max": 1300.00,
    "std": 25.43
  }
}
```

**Hints:**
- Use pandas `describe()` method
- Add to backend response dict

### Exercise 3: Add Caching
Dodaj caching to frontendu aby nie odpytywaÄ‡ API wielokrotnie:
```python
@st.cache_data(ttl=3600)  # Cache for 1 hour
def get_predictions(item_name: str):
    ...
```

**Test:** Czy drugi request for tego samego produktu jest szybszy?

## ğŸ” Troubleshooting

### Problem: "ModuleNotFoundError"
**Solution:**
```bash
cd backend/  # or frontend/
uv sync
```

### Problem: "Address already in use"
**Solution:** Another process is using port 8003 or 8501
```bash
# Find process
lsof -ti:8003    # for backendu
lsof -ti:8501    # for frontendu

# Kill process
lsof -ti:8003 | xargs kill -9
```

### Problem: "Connection refused" in frontend
**Solution:** Backend is not running
```bash
# W osobnym terminalu
cd backend/
uv run uvicorn main:app --host 0.0.0.0 --port 8003
```

### Problem: DÅ‚ugi startup time
**Oczekiwane:** Pierwsze uruchomienie backendu trwa 5-10 seconds (loading modelu)

**Check logi:**
```
INFO: Loading AutoGluon predictor...    â† Should appear
INFO: Predictor loaded successfully      â† Should complete
```

## ğŸ“Š Performance Benchmarks

**Typowe wartoÅ›ci (MacBook Pro M1):**

| Metric | Value | Notes |
|--------|-------|-------|
| Backend startup | 5-8s | Model loading |
| First request | 300-500ms | Cold start |
| Subsequent requests | 150-250ms | Model in memory |
| Frontend load | 1-2s | Streamlit initialization |
| UI interaction | <100ms | Local network |

## ğŸ”— Next Steps

When you master local development:

1. **[Stage 2: Docker](../2-docker/README.md)**
   - Containerization
   - Reproducible environments
   - Docker Compose for multi-container apps

2. **[Stage 3: Cloud](../3-cloud/README.md)**
   - GCP Cloud Run deployment
   - Serverless architecture
   - Production-ready patterns

## ğŸ’¡ Additional Resources

### Documentation
- [FastAPI Tutorial](https://fastapi.tiangolo.com/tutorial/)
- [Streamlit Quickstart](https://docs.streamlit.io/get-started)
- [AutoGluon TimeSeries](https://auto.gluon.ai/stable/tutorials/timeseries/index.html)

### Concepts
- [Microservices Architecture](https://microservices.io/)
- [RESTful API Design](https://restfulapi.net/)
- [HTTP Status Codes](https://httpstatuses.com/)

### Tools
- [Postman](https://www.postman.com/) - API testing tool
- [curl](https://curl.se/) - Command-line HTTP client
- [uv](https://github.com/astral-sh/uv) - Fast Python package manager

## ğŸ¯ Summary

**What we learned:**
- âœ… Microservices architecture (backend + frontend)
- âœ… RESTful API design with FastAPI
- âœ… Interactive UI with Streamlit
- âœ… HTTP communication between services
- âœ… Performance optimization (startup loading)
- âœ… Error handling and UX patterns
- âœ… Modern Python tooling (uv)

**What's next:**
- ğŸ³ Docker containerization
- â˜ï¸ Cloud deployment
- ğŸ“Š Load testing
- ğŸ”’ Authentication
- ğŸ“ˆ Monitoring

**Key Takeaway:** Local development is the foundation. Master it before moving to containers and cloud!
